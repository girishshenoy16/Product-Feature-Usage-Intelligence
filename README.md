# ğŸ“˜ Product Feature Usage Intelligence Dashboard

### *End-to-End Business Analyst Project (Python â€¢ Streamlit â€¢ RFM â€¢ KMeans â€¢ Plotly)*

---

# ğŸ“Œ **1. Project Overview**

This project simulates a **real SaaS product analytics workflow**, where we analyze how users interact with different product features over time.

The system provides:

* Feature usage metrics
* User engagement analytics
* RFM-based behavioral scoring
* KMeans usage segmentation
* A polished multi-page Streamlit dashboard

This project is designed for **Business Analyst / Product Analyst / Data Analyst** roles and is fully runnable locally.

---

# ğŸ“Œ **2. Problem Statement & Business Context**

Modern digital products generate large volumes of event-level data (clicks, searches, feature interactions).
However, companies often struggle with:

* Understanding which features are actually used
* Identifying â€œpower usersâ€ vs â€œat-riskâ€ users
* Measuring adoption and engagement
* Making data-driven product decisions

This project solves that by simulating:

* Feature-level adoption
* Usage trends
* RFM-based engagement scoring
* Usage-based user segmentation
* Monitoring active vs inactive users

Product Managers, Growth Teams, and Analysts use dashboards like this to:

* Prioritize the roadmap
* Improve user retention
* Identify adoption gaps
* Personalize engagement or marketing campaigns

---

# ğŸ“Œ **3. Tech Stack**

**Programming & Analytics**

* Python 3.10+
* Pandas, NumPy
* scikit-learn (KMeans segmentation)
* Plotly (interactive visuals)

**App / UI**

* Streamlit (multi-page dashboard)

**Utilities**

* Joblib
* Pytest (for model testing)

---

# ğŸ“Œ **4. Data Description**

Synthetic dataset simulates clickstream-like product usage:

### **Raw Data Columns**

| Column         | Description                                 |
| -------------- | ------------------------------------------- |
| `user_id`      | Unique user ID                              |
| `signup_date`  | When the user joined                        |
| `event_date`   | Date of feature usage                       |
| `feature_name` | Feature used (Search, Dashboard, API, etc.) |
| `events_count` | Number of actions for that feature/day      |

### **Processed Data Columns**

| Column            | Description                    |
| ----------------- | ------------------------------ |
| `last_event_date` | Last active day                |
| `active_days`     | Days user engaged with product |
| `total_events`    | Total feature interactions     |
| `recency`         | Days since last activity       |
| `frequency`       | Number of active days          |
| `monetary`        | Usage intensity score          |
| `cluster`         | KMeans behavioral segment      |

---

# ğŸ“Œ **5. Architecture**

```
Synthetic Feature Usage Data
          â†“
Preprocessing (clean, transform, aggregate)
          â†“
RFM Feature Builder (recency / frequency / monetary)
          â†“
KMeans Segmentation Model (Power, Regular, At-Risk, Dormant)
          â†“
Streamlit Multi-Page Dashboard
          â†“
Insights for Product & Business Decision-Making
```

---

ğŸ“ Folder Structure

```
Product-Feature-Usage-Intelligence/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Home.py
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 1_Overview.py
â”‚       â”œâ”€â”€ 2_Feature_Usage.py
â”‚       â””â”€â”€ 3_RFM_Segments.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ kmeans_rfm.pkl
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_synthetic_data.py
â”‚   â”œâ”€â”€ preprocess_data.py
â”‚   â”œâ”€â”€ build_rfm.py
â”‚   â””â”€â”€ train_model.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ rfm.py
â”‚   â””â”€â”€ viz.py
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_predict.py
â”‚
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ overview.png
â”‚   â”œâ”€â”€ feature_usage.png
â”‚   â””â”€â”€ rfm_segments.png
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

# ğŸ“Œ **6. How to Run (Step-by-step)**

### **1ï¸âƒ£ Clone the repository**

```bash
git clone https://github.com/girishshenoy16/product_feature_intel.git
cd Product_Feature_Intel
```

### **2ï¸âƒ£ Create a virtual environment**

```bash
python -m venv venv
venv\Scripts\activate
```

### **3ï¸âƒ£ Install dependencies**

```bash
python.exe -m pip install --upgrade pip
pip install -r requirements.txt
```

### **4ï¸âƒ£ Generate synthetic data**

```bash
python scripts/generate_synthetic_data.py
```

### **5ï¸âƒ£ Preprocess / build features**

```bash
python scripts/preprocess_data.py
python scripts/build_rfm.py
```

### **6ï¸âƒ£ Train KMeans model**

```bash
python scripts/train_model.py
```

### **7ï¸âƒ£ Evaluate KMeans model**

```bash
python src/evaluate_model.py
```

### **8ï¸âƒ£ Testing the project**

```bash
pytest -v
```

### **9ï¸âƒ£ Start the dashboard**

```bash
streamlit run app/Home.py
```

Your dashboard opens at:
ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

---

# ğŸ“Œ **7. Dashboard Walkthrough (with screenshots)**

### **ğŸ  Home Page**

Simple project overview and navigation.

---

### **ğŸ“Œ Overview Page**

Shows high-level KPIs:

* Total users
* Avg events per user
* Avg active days
* RFM summary per cluster


```
![Overview](screenshots/overview.png)
```

---

### **ğŸ“ˆ Feature Usage Page**

Includes:

* Total usage per feature
* Interactive filters (date range, feature selection)
* Feature-wise time-series trends


```
![Feature Usage](screenshots/feature_usage.png)
```

---

### **ğŸ§® RFM Segments Page**

* 3D RFM scatter plot (Recencyâ€“Frequencyâ€“Monetary)
* Cluster distribution bar chart
* Insightful cluster interpretation


```
![RFM Segments](screenshots/rfm_segments.png)
```

---

# ğŸ“Œ **8. Key Insights & Results**

Some example insights (your numbers may differ):

### ğŸ”¹ Feature Usage

* "Dashboard" is the most used feature.
* API & Integrations have lower adoption (good candidate for UX improvement).

### ğŸ”¹ Engagement (RFM)

* Power users show low recency and high frequency/monetary.
* At-risk users show high recency with declining frequency.

### ğŸ”¹ Segments

Model successfully separates users into:

* **Cluster 0 â€“ Power Users**
* **Cluster 1 â€“ Regular Users**
* **Cluster 2 â€“ At-Risk Users**
* **Cluster 3 â€“ Dormant Users**

These are directly usable for:

* Re-engagement campaigns
* Feature onboarding
* Product roadmap planning

---

# ğŸ“Œ **9. Future Work**

To expand this into a more advanced product analytics suite:

* ğŸ“‰ **Churn prediction model**
* ğŸ§© **Cohort retention heatmaps**
* âš¡ Real-time usage ingestion (Kafka â†’ DB â†’ Dashboard)
* ğŸ“Š Feature correlation matrix (which features drive stickiness?)
* ğŸ§­ User journey funnel visualization
* ğŸš€ Deploy dashboard to Streamlit Cloud / Render / AWS
